# Components



# Error Cases

- Chunk size too big
-> Hardcapped to 2000 tokens (tiktoken)

# Notes on LLama
- Request Meta and Huggingface
- Huggingface Account, add Huggingface Token, + transformers
- 10GB, pip install accelerate, saved within global cache, not dependent on virtualenv